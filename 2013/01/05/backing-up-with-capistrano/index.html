<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  
    <title>Backing up with Capistrano - Keith Smiley</title>
  

    <meta name="author" content="Keith Smiley">
    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/atom.xml">

    <link rel="icon" href="/images/favicon.png" type="image/x-icon">
    <link rel="shortcut icon" href="/images/favicon.png" type="image/x-icon">

    <link rel="stylesheet" type="text/css" href="/css/style.css" title="default">
  </head>
  <body>
    <section class="container">
      <div id="masthead">
        <h1>
          <a href="/">Keith Smiley</a>
          | <a href="https://www.keith.so">About</a>
          | <a href="/atom.xml">RSS</a>
        </h1>
      </div>

      <section class="content">
        <article>
  <header class="seven columns">
    
      <h1 class="title">Backing up with Capistrano</h1>
    
    <p class="date">
      <time datetime="2013-01-05 12:12:00 -0800" pubdate="pubdate">
        05 Jan 2013
      </time>
      <a class="permalink" title="Permalink" href="/2013/01/05/backing-up-with-capistrano/">&infin;</a>
    </p>
  </header>

  <div class="post ten columns">
    <p>We all know not backing up has <a href="http://www.wired.com/gadgetlab/2012/08/apple-amazon-mat-honan-hacking/">consequences</a>. While losing sentimental files would definitely ruin your day, losing your web server's data could be even worse. I've mentioned <a href="http://smileykeith.com/2013/01/02/linode-setup/">before</a> that I use <a href="http://www.linode.com/?r=c190426bf1ff0f144b48997675bae8b32d339824">Linode</a> for my server hosting, and while they do offer an <a href="http://library.linode.com/backup-service">automated backup service</a> I decided I'd rather setup my own solution to back up periodically to my local machine.</p>

<p>Many people use <a href="http://en.wikipedia.org/wiki/Rsync">rsync</a> to do their server backups. In fact Linode even has a <a href="http://library.linode.com/linux-tools/utilities/rsync#sph_use-rsync-to-back-up-production-environments">guide</a> on how to set it up (there's a better one <a href="http://feross.org/how-to-setup-your-linode/">here</a>). I decided that instead of a 1 for 1 directory backup, I would prefer to have a <a href="http://en.wikipedia.org/wiki/Tar_(file_format)">tarball</a> of the contents. While I could've easily done this with a few bash commands from the server that's not particular ideal for my setup. My local machines don't run 24/7 so if I set it up on the server to automate the backup every week, it may try to initiate the backup when my machine was off (I could try to guess when it's on every week but that's not ideal either).</p>

<p>The obvious solution to this is run it from my local machine instead every week. That way once a week when it's powered up it would log in to the server, create the tarball and pull it down. Insert <a href="https://github.com/capistrano/capistrano">Capistrano</a> (<code class="language-plaintext highlighter-rouge">[sudo] gem install capistrano</code>) a <a href="http://rubygems.org/">RubyGem</a> for 'Remote multi-server automation.' So I wrote a very basic <code class="language-plaintext highlighter-rouge">Capfile</code> to automate this for me (replace the path to your <code class="language-plaintext highlighter-rouge">www</code> folder accordingly).</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">load</span> <span class="s1">'deploy'</span>

<span class="vg">$SERVER_USER</span> <span class="o">=</span> <span class="s2">"username"</span>
<span class="vg">$SERVER_IP</span>   <span class="o">=</span> <span class="s2">"1.1.1.1"</span>

<span class="n">desc</span> <span class="s2">"Backs up server www files"</span>
<span class="n">task</span> <span class="ss">:backup</span><span class="p">,</span> <span class="ss">:hosts</span> <span class="o">=&gt;</span> <span class="vg">$SERVER_IP</span> <span class="k">do</span>
  <span class="n">run</span> <span class="s2">"cd /srv; tar -pvczf ~/backup.tar.gz www/"</span>
  <span class="n">run_locally</span> <span class="s2">"scp </span><span class="si">#{</span> <span class="vg">$SERVER_USER</span> <span class="si">}</span><span class="s2">@</span><span class="si">#{</span> <span class="vg">$SERVER_IP</span> <span class="si">}</span><span class="s2">:~/backup.tar.gz ~/Dropbox/Backups/Server"</span>
<span class="k">end</span></code></pre></figure>

<p>Then I added this to my crontab on my local machine by running <code class="language-plaintext highlighter-rouge">crontab -e</code> and adding the line:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">@weekly /Users/ksmiley/.rbenv/shims/cap <span class="nt">-f</span> ~/path/to/Capfile backup</code></pre></figure>

<p>I included the path to the Capistrano executable since cron (on OS X) executes tasks with <code class="language-plaintext highlighter-rouge">sh</code>, which isn't setup with my <code class="language-plaintext highlighter-rouge">$PATH</code>.</p>


  </div>
</article>

      </section>
    </section>
  </body>
</html>
